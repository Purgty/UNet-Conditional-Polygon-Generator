# Ayna UNET Model ğŸ¨

A deep learning model that colorizes grayscale polygon images based on a given color name using a custom-built **Conditional UNet** architecture.

## ğŸš€ Features

- **Conditional UNet**: Color embedding fused into UNet bottleneck.
- **Mixed Precision Training**: Faster training with `torch.cuda.amp`.
- **Transfer Learning Support**: Resume from pretrained checkpoints.
- **Flexible Inference**: Predict single or batch of images.
- **WandB Integration**: Track experiments, losses & predictions.

## ğŸ§  Model Overview

- **Encoder**: Downsample grayscale input into deep features.
- **Color Embedding**: Encoded via `nn.Embedding`.
- **Bottleneck**: Color vector concatenated with deep features.
- **Decoder**: Upsamples with skip connections.
- **Output**: RGB image via final convolution.

## ğŸ“¦ Installation

```bash
git clone https://github.com/YOUR_USERNAME/Ayna-UNET-Model.git
cd Ayna-UNET-Model

conda create -n ayna python=3.10
conda activate ayna

pip install torch torchvision torchaudio wandb matplotlib numpy Pillow
```

## ğŸ“ Dataset Structure

```
dataset/
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ inputs/
â”‚   â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ data.json
â””â”€â”€ validation/
    â”œâ”€â”€ inputs/
    â”œâ”€â”€ outputs/
    â””â”€â”€ data.json
```

Each `data.json` contains mappings of:
```json
{ "input_polygon": "octagon.png", "colour": "red", "output_image": "red_octagon.png" }
```

## ğŸ‹ï¸ Training

Edit hyperparams in `train.py` and run:

```bash
python train.py
```

## â™»ï¸ Transfer Learning

To fine-tune from a checkpoint, set `pretrained_model_path` in `train.py`.

## ğŸ–¼ï¸ Inference

Set `model_path`, `input_image_path`, and `colour` in `inference.py`, then run:

```bash
python inference.py
```

The final model used for inference is conditional_unet_50mod.pth in this repo.
## ğŸ›  Troubleshooting

- **State Dict Mismatch**: Ensure `embed_dim` and `img_size` match between training and inference configs.
- **CUDA OOM**: Reduce `batch_size` or `img_size`.
